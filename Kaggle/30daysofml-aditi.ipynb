{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reading the training and test data in csv files as pandas dataframes\n\nkaggle_train = pd.read_csv('../input/30-days-of-ml/train.csv')\n\nkaggle_test = pd.read_csv('../input/30-days-of-ml/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the first few rows of kaggle_train dataframe\n\nkaggle_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output of code expression above shows the index column as the first column. So, the dataframe can be indexed using this column and cat0 will become the first column after indexing is done. ","metadata":{}},{"cell_type":"code","source":"# changing the index of kaggle_train dataframe to values in the 'id' column\n\nkaggle_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col = 'id')\n\nkaggle_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the first few rows of kaggle_test dataframe\n\nkaggle_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Similarly, changing the index of kaggle_test dataframe to values in the 'id' column\n\nkaggle_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col = 'id')\n\nkaggle_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the number of observations in kaggle_train dataframe\n\nkaggle_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the number of observations in kaggle_test dataframe\n\nkaggle_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the information about kaggle_train dataframe\n\nkaggle_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the target variable 'target', which is required to be predicted is a continuous variable, this particular competition assignment is a regression problem. There are 10 categorical features and 14 continuous features in the dataset. Moreover, the size of kaggle_train dataframe is large that leaves enough scope for segregation of this dataframe into training and validation sets for training a regression model using different algorithms and then successfully choosing model with lowest values of root mean square error. This model will then be used on kaggle_test dataframe for making the final submission to the competition. ","metadata":{}},{"cell_type":"code","source":"# checking the statistical summary of kaggle_train dataframe\n\nkaggle_train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interpretation:\n\nIt can be clearly observed in the statistical summary that there is difference between mean and median values in almost all the columns with numerical values except 'cont2' column in which mean value is quite close to the median value. Therefore, it can be inferred at this stage that the distribution of data in almost all the numerical columns does not follow Gaussian distribution. However, the distribution will also be visually observed in the plots later in this competition assignment file. ","metadata":{}},{"cell_type":"code","source":"# checking whether there are any missing values in kaggle_train dataframe\n\nkaggle_train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output of above code expression suggests that there are no missing values in each of the columns in kaggle_train dataframe. ","metadata":{}},{"cell_type":"code","source":"# checking whether there are any missing values in kaggle_test dataframe\n\nkaggle_test.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output of above code expression suggests that there are also no missing values in each of the columns in kaggle_test dataframe. ","metadata":{}},{"cell_type":"markdown","source":"Important Observation: \n\nThe 'overview' section of the competition page gives the information that the target variable i.e.; 'target' column contains the values that refer to the amount of insurance claim and the task is to build regression model that can predict this amount with lowest possible root mean square error. However, all the features in training and test data are unnamed and thus, their meaning cannot be inferred to understand their signifcance with respect to insurance claim amount. The given competition data is a labeled data as the meaning of target variable is known to us. Since the features either contain alphabetical letters or float values, it is quite difficult to discern the meaning of the features even if someone has knowledge about insurance domain. \n\nIn case of a dataset with unknown features, it is suggested to perform principal component analysis to make meaning out of these unknown features. Please check this link for reference: https://medium.com/@studyammu/how-to-do-feature-engineering-when-you-have-unknown-features-d369e6f8cdf6\n\nMoreover, cross-validation technique is not suitable to implement on this particular dataset as it was recommended in the Kaggle's tutorial on 'Cross-validation' that cross-validation can increase the computational time in case of larger datasets, which is given to us in this competition assignment. \n","metadata":{}},{"cell_type":"code","source":"# importing the necessary packages for data  visualization\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Study of the values in features in training data**","metadata":{}},{"cell_type":"code","source":"kaggle_train['cat0'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 2 values in 'cat0' column - A and B","metadata":{}},{"cell_type":"code","source":"# visualizing the count of values of categories in 'cat0' column\nsns.countplot(y = 'cat0', data = kaggle_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing the relationship of 'cat0' with 'target'\n\nsns.catplot(x= 'cat0', y= 'target', data= kaggle_train, kind=\"boxen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows that the categories in 'cat0' do not perform a good job when it comes to distinguishing values in 'target'. The distributions look similar. ","metadata":{}},{"cell_type":"code","source":"kaggle_train['cat1'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 2 values in 'cat1' column - A and B","metadata":{}},{"cell_type":"code","source":"# visualizing the count of values of categories in 'cat1' column\n\nsns.countplot(y = 'cat1', data = kaggle_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing the relationship of 'cat1' with 'target'\n\nsns.catplot(x= 'cat1', y= 'target', data= kaggle_train, kind=\"boxen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows that the categories in 'cat1' do not perform a good job when it comes to distinguishing values in 'target'. The distributions look similar. ","metadata":{}},{"cell_type":"code","source":"kaggle_train['cat2'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 2 values in 'cat2' column - A and B","metadata":{}},{"cell_type":"code","source":"# visualizing the count of values of categories in 'cat2' column\n\nsns.countplot(y = 'cat2', data = kaggle_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing the relationship of 'cat2' with 'target'\n\nsns.catplot(x= 'cat2', y= 'target', data= kaggle_train, kind=\"boxen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows that the categories in 'cat2' do not perform a good job when it comes to distinguishing values in 'target'. The distributions look similar. ","metadata":{}},{"cell_type":"code","source":"kaggle_train['cat3'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 4 values in 'cat3' column - A, B, C, and D","metadata":{}},{"cell_type":"code","source":"# visualizing the count of values of categories in 'cat3' column\nsns.countplot(y = 'cat3', data = kaggle_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing the relationship of 'cat3' with 'target'\n\nsns.catplot(x= 'cat3', y= 'target', data= kaggle_train, kind=\"boxen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows that the categories in 'cat3' do not perform a good job when it comes to distinguishing values in 'target'. The distributions look similar. ","metadata":{}},{"cell_type":"code","source":"kaggle_train['cat4'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 4 values in 'cat4' column - A, B, C, and D","metadata":{}},{"cell_type":"code","source":"# visualizing the count of values of categories in 'cat4' column\n\nsns.countplot(y = 'cat4', data = kaggle_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing the relationship of 'cat4' with 'target'\n\nsns.catplot(x= 'cat4', y= 'target', data= kaggle_train, kind=\"boxen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows that the categories in 'cat4' do not perform a good job when it comes to distinguishing values in 'target'. The distributions look similar. ","metadata":{}},{"cell_type":"code","source":"kaggle_train['cat5'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 4 values in 'cat5' column - A, B, C and D","metadata":{}},{"cell_type":"code","source":"#  visualizing the count of values of categories in 'cat5' column\n\nsns.countplot(y = 'cat5', data = kaggle_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing the relationship of 'cat5' with 'target'\n\nsns.catplot(x= 'cat5', y= 'target', data= kaggle_train, kind=\"boxen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows that the categories in 'cat5' do not perform a good job when it comes to distinguishing values in 'target'. The distributions look similar. ","metadata":{}},{"cell_type":"code","source":"kaggle_train['cat6'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 8 values in 'cat6' column - A, B, C, D, E, G, H, I","metadata":{}},{"cell_type":"code","source":"#  visualizing the count of values of categories in 'cat6' column\n\nplt.figure(figsize=(10, 10))\nsns.countplot(y = 'cat6', data = kaggle_train)\nplt.xlim(5, 300000)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing the relationship of 'cat6' with 'target'\n\nsns.catplot(x= 'cat6', y= 'target', data= kaggle_train, kind=\"boxen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows that the categories in 'cat6' do not perform a good job when it comes to distinguishing values in 'target'. The distributions look similar. ","metadata":{}},{"cell_type":"code","source":"kaggle_train['cat7'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 8 values in 'cat7' column - A, B, C, D, E, F, G, I","metadata":{}},{"cell_type":"code","source":"#  visualizing the count of values of categories in 'cat7' column\n\nsns.countplot(y = 'cat7', data = kaggle_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing the relationship of 'cat7' with 'target'\n\nsns.catplot(x= 'cat7', y= 'target', data= kaggle_train, kind=\"boxen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows that the categories in 'cat7' do not perform a good job when it comes to distinguishing values in 'target'. The distributions look similar. ","metadata":{}},{"cell_type":"code","source":"kaggle_train['cat8'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 7 values in 'cat8' column - A, B, C, D, E, F, G","metadata":{}},{"cell_type":"code","source":"#  visualizing the count of values of categories in 'cat8' column\n\nsns.countplot(y = 'cat8', data = kaggle_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing the relationship of 'cat8' with 'target'\n\nsns.catplot(x= 'cat8', y= 'target', data= kaggle_train, kind=\"boxen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows that the categories in 'cat8' do not perform a good job when it comes to distinguishing values in 'target'. The distributions look similar. ","metadata":{}},{"cell_type":"code","source":"kaggle_train['cat9'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 15 values in 'cat9' column - the alphabetical sequence of letters from A to O","metadata":{}},{"cell_type":"code","source":"#  visualizing the count of values of categories in 'cat9' column\n\nplt.figure(figsize = (10, 10))\nsns.countplot(y = 'cat9', data = kaggle_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing the relationship of 'cat9' with 'target'\n\nplt.figure(figsize = (10, 10))\nsns.catplot(x= 'cat9', y= 'target', data= kaggle_train, kind=\"boxen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows that the categories in 'cat9' do not perform a good job when it comes to distinguishing values in 'target'. The distributions look similar.","metadata":{}},{"cell_type":"markdown","source":"Next step: Selecting the numerical columns from kaggle_train dataframe to visualise the distribution of data in each of these columns and check the relations between each of these features and the target variable using regression plots ","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont0' column\n\nsns.distplot(kaggle_train['cont0'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot shows that the data in 'cont0' column follows close to Gaussian distribution but Shapiro test will verify whether it follows Gaussian distribution or not.  ","metadata":{}},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution\n\nfrom scipy import stats\n\n# conducting Shapiro Wilk test on numerical values in 'cont0' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont0'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont0']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont0']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont0' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont0' and 'target'\n\nsns.regplot(x = kaggle_train['cont0'], y = kaggle_train['target'])\nplt.xlabel(\"cont0\")\nplt.ylabel(\"target\")\nplt.title('cont0 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont0' and 'target' ","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont1' column\n\nsns.distplot(kaggle_train['cont1'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows that the data in 'cont1' follows close to Gaussian distribution but Shapiro test will verify whether it follows Gaussian distribution or not.  ","metadata":{}},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont1' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont1'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont1']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont1']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Result - 'cont1' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont1' and 'target'\n\nsns.regplot(x = kaggle_train['cont1'], y = kaggle_train['target'])\nplt.xlabel(\"cont1\")\nplt.ylabel(\"target\")\nplt.title('cont1 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont1' and 'target' ","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont2' column\n\nsns.distplot(kaggle_train['cont2'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont2' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont2'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont2']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont2']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont2' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont2' and 'target'\nplt.figure(figsize = (10, 10))\nsns.regplot(x = kaggle_train['cont2'], y = kaggle_train['target'])\nplt.xlabel(\"cont2\")\nplt.ylabel(\"target\")\nplt.title('cont2 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont2' and 'target' ","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont3' column\n\nsns.distplot(kaggle_train['cont3'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont3' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont3'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont3']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont3']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont3' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont3' and 'target'\n\nsns.regplot(x = kaggle_train['cont3'], y = kaggle_train['target'])\nplt.xlabel(\"cont3\")\nplt.ylabel(\"target\")\nplt.title('cont3 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont3' and 'target' ","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont4' column\n\nsns.distplot(kaggle_train['cont4'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot clearly shows that distribution of data in 'cont4' column is right-skewed and hence, the data does not follow Gaussian distribution. ","metadata":{}},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont4' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont4'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont4']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont4']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont4' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont4' and 'target'\n\nsns.regplot(x = kaggle_train['cont4'], y = kaggle_train['target'])\nplt.xlabel(\"cont4\")\nplt.ylabel(\"target\")\nplt.title('cont4 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont4' and 'target' ","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont5' column\n\nsns.distplot(kaggle_train['cont5'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont5' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont5'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont5']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont5']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont5' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont5' and 'target'\n\nsns.regplot(x = kaggle_train['cont5'], y = kaggle_train['target'])\nplt.xlabel(\"cont5\")\nplt.ylabel(\"target\")\nplt.title('cont5 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont5' and 'target' ","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont6' column\n\nsns.distplot(kaggle_train['cont6'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows that distribution of data in 'cont6' column but it needs to be verified by using Shapiro test. ","metadata":{}},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont6' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont6'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont6']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont6']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont6' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont6' and 'target'\n\nsns.regplot(x = kaggle_train['cont6'], y = kaggle_train['target'])\nplt.xlabel(\"cont6\")\nplt.ylabel(\"target\")\nplt.title('cont6 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont6' and 'target'","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont7' column\n\nsns.distplot(kaggle_train['cont7'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont7' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont7'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont7']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont7']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont7' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont7' and 'target'\n\nsns.regplot(x = kaggle_train['cont7'], y = kaggle_train['target'])\nplt.xlabel(\"cont7\")\nplt.ylabel(\"target\")\nplt.title('cont7 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont7' and 'target'","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont8' column\n\nsns.distplot(kaggle_train['cont8'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows that the data in 'cont8' column is left-skewed and thus, the data does not follow Gaussian distribution. ","metadata":{}},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont8' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont8'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont8']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont8']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont8' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont8' and 'target'\n\nsns.regplot(x = kaggle_train['cont8'], y = kaggle_train['target'])\nplt.xlabel(\"cont8\")\nplt.ylabel(\"target\")\nplt.title('cont8 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont8' and 'target'","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont9' column\n\nsns.distplot(kaggle_train['cont9'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont9' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont9'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont9']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont9']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont9' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont9' and 'target'\n\nsns.regplot(x = kaggle_train['cont9'], y = kaggle_train['target'])\nplt.xlabel(\"cont9\")\nplt.ylabel(\"target\")\nplt.title('cont9 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont9' and 'target'","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont10' column\n\nsns.distplot(kaggle_train['cont10'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont10' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont10'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont10']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont10']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont10' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont10' and 'target'\n\nsns.regplot(x = kaggle_train['cont10'], y = kaggle_train['target'])\nplt.xlabel(\"cont10\")\nplt.ylabel(\"target\")\nplt.title('cont10 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont10' and 'target'","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont11' column\n\nsns.distplot(kaggle_train['cont11'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont11' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont11'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont11']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont11']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont11' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont11' and 'target'\n\nsns.regplot(x = kaggle_train['cont11'], y = kaggle_train['target'])\nplt.xlabel(\"cont11\")\nplt.ylabel(\"target\")\nplt.title('cont11 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont11' and 'target'","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont12' column\n\nsns.distplot(kaggle_train['cont12'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont12' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont12'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont12']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont12']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont12' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont12' and 'target'\n\nsns.regplot(x = kaggle_train['cont12'], y = kaggle_train['target'])\nplt.xlabel(\"cont12\")\nplt.ylabel(\"target\")\nplt.title('cont12 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont12' and 'target'","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in 'cont13' column\n\nsns.distplot(kaggle_train['cont13'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'cont13' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['cont13'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['cont13']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['cont13']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'cont13' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# making a regression plot between 'cont13' and 'target'\n\nsns.regplot(x = kaggle_train['cont13'], y = kaggle_train['target'])\nplt.xlabel(\"cont13\")\nplt.ylabel(\"target\")\nplt.title('cont13 vs target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plot shows there is no strong linear relationship between 'cont13' and 'target'","metadata":{}},{"cell_type":"markdown","source":"Observations: \n\nThus, we have analysed all the numerical columns in training data with respect to their data distribution and each of their relations with the target variable, 'target'. This analysis suggests that the data is not normally distributed in each of these columns and each of them also does not have a strong linear relationship with the target variable as observed in regression plots. ","metadata":{}},{"cell_type":"code","source":"# visualizing the distribution of data in target variable 'target'\n\nsns.distplot(kaggle_train['target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the values in column follow normal distribution by using Shapiro test\n# Null hypothesis is that the column data values follow normal distribution\n# If p-value > 0.05, the data follows normal distribution\n# If p-value <= 0.05 then the data does not follow normal distribution. \n\n# conducting Shapiro Wilk test on numerical values in 'target' column of kaggle_train to check whether the values\n# follow Gaussian distribution.\n\nshap_t, shap_p = stats.shapiro(kaggle_train['target'])\n\nprint(\"Skewness : %f\" % abs(kaggle_train['target']).skew())\nprint(\"Kurtosis : %f\" % abs(kaggle_train['target']).kurt())\nprint(\"Shapiro_Test: %f\" % shap_t)\nprint(\"Shapiro_Test: %f\" % shap_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Result - 'target' does not follow Gaussian distribution as p-value is less than 0.05","metadata":{}},{"cell_type":"code","source":"# checking the relation between numerical variables by using correlation\n\nselect_var = kaggle_train.select_dtypes(include = ['float64'])\n\nkaggle_corr = select_var.corr()\n\nkaggle_corr     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# arranging the correlation values in descending order w.r.t. target variable, 'target'\n\nkaggle_corr['target'].sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'cont12' and 'cont10' are most correlated with the target variable among other independent variables. However, values of +0.05 for bot the variables are still low than the threshold for considering these values a strong correlation. ","metadata":{}},{"cell_type":"markdown","source":"Interpretation:\n\nThe output of above code expression again shows that there is no strong linear relation between independent numerical features and the target variable and also, it is observed that there is no strong linear relation between independent numerical variables too. Hence, linear regression algorithm cannot be implemented to make predictions in case of this dataset that is given in the competition assignment. The concept of 'Mutual Information', which is used in feature engineering to identify any kind of relationship between the independent variable and the target that is not usually identified in correlation methods. However, the mutual information only can function of dataframes with discrete values as integers and continuous values. Hence, the kaggle_train dataframe needs to be copied and the object data types in copy of kaggle_train dataframe need to be converted into discrete integer values to apply mutual information technique and identify the relationships.  ","metadata":{}},{"cell_type":"code","source":"# making a copy of kaggle_train dataframe\n\nkaggle_tr = kaggle_train.copy(deep = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# separating features and label in copy of kaggle_train dataframe i.e.; kaggle_tr\n\nkaggle_features = kaggle_tr.drop(['target'], axis = 1)\n\nkaggle_label = kaggle_tr['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the first few observations of kaggle_features\n\nkaggle_features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the first few observations of kaggle_label\n\nkaggle_label.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding the categorical variables as discrete variables by converting them into integer values \n\nfor cols in kaggle_features.select_dtypes(include = ['object']).columns:\n    kaggle_features[cols], _ = kaggle_features[cols].factorize()\n    \ndiscrete_features = kaggle_features.dtypes == 'int'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the observations in discrete_features to verify the implementation of necessary changes in\n# the first 10 columns of kaggle_features dataframe\n\ndiscrete_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since this competition assignment is regression problem in which the task is to \n# predict the values of continuous variable, 'target'. Hence, we are importing mutual_info_regression \n# package from scikit-learn\n\nfrom sklearn.feature_selection import mutual_info_regression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining a function for calculating mutual information scores of independent variables in \n# kaggle_features that signify the strength of each of their \n# relations with the target variable, 'target' in kaggle_label\n\ndef return_mi_scores(kaggle_features, kaggle_label, discrete_features):\n    mi_scores = mutual_info_regression(kaggle_features, kaggle_label, \n                                       discrete_features = discrete_features)\n    mi_scores = pd.Series(mi_scores, name = 'MI Scores', index = kaggle_features.columns)\n    mi_scores = mi_scores.sort_values(ascending = False)\n    return mi_scores\n\n# using the above defined function to get mutual information scores\n\nmi_scores = return_mi_scores(kaggle_features, kaggle_label, discrete_features)\n\nmi_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observations:\n\nThe output of above code expression has not given assuring results with respect to mutual information scores. All the values except one are very close to 0, which indicates the independence between the feature and the target variable and thus, the features carry little significance for prediction of target variable. 'cont12' has the highest mutual information score that is approximately equal to 0.02 and it is also not very significant for prediction of target variable. We will make a relational plot to further observe the relations between 'cont12' and 'target'. \n\nIn addition, if the features are required to made significant for prediction, they should be transformed by the use of feature engineering. However, feature engineering can be carried out by analysts not just by having a data-driven perspective but by taking into account the relevant information such as problem-specific industry domain and details about features present in the dataset. This approach is called as manual feature engineering. \n\nHowever, the features given in the dataset as part of this competition assignment are unknown and thus, it may not be feasible to carry out manual feature engineering even if someone has industry domain knowledge. Since feature transformation is crucial for making predictions, automated feature engineering will be carried out in this case. ","metadata":{}},{"cell_type":"code","source":"# making relational plot between 'target' and 'cont12', which has the highest mutual information score\n# as observed in the output of previous code expression\n\nsns.relplot(x = 'cont12', y = 'target', data = kaggle_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot does not show a definite relation between 'cont12' and 'target' ","metadata":{}},{"cell_type":"code","source":"'''splitting the kaggle_tr into training and validation sets to build a baseline \nmodel and later use Automated feature engineering to build an improved model and evaluate it \nwith respect to the baseline model'''\n\n# importing the necessary packages \n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n# as the competition guidelines indicate that root mean square error is the metric \n# for evaluating the model for making predictions, we are importing mean_squared_error \n# from scikit-learn package. mean_squared_error function has a boolean argument 'squared'. \n# If the value of 'squared' is chosen as 'False' then, the mean_squared_error function\n# calculates root mean squared error\n\nfrom sklearn.metrics import mean_squared_error\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since columns from 'cat0' to 'cat9' contain categorical values and that too as alphabetical letter, these values can be accordingly encoded according to the position of a particular alphabet in the alphabetical sequence to clearly indicate the alphabetical letter.\n\n1. 'cat0' - 'A' and 'B' can be changed to 1 and 2 respectively. \n2. 'cat1' - 'A' and 'B' can be changed to 1 and 2 respectively. \n3. 'cat2' - 'A' and 'B' can be changed to 1 and 2 respectively. \n4. 'cat3' - 'A', 'B', 'C' and 'D' can be changed to 1, 2, 3 and 4 respectively. \n5. 'cat4' - 'A', 'B', 'C' and 'D' can be changed to 1, 2, 3 and 4 respectively. \n6. 'cat5' - 'A', 'B', 'C' and 'D' can be changed to 1, 2, 3 and 4 respectively. \n7. 'cat6' - 'A', 'B', 'C', 'D', 'E', 'G', 'H', 'I' can be changed to 1, 2, 3, 4, 5, 6, 7, 8 respectively. \n8. 'cat7' - 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I' can be changed to 1, 2, 3, 4, 5, 6, 7, 8 respectively. \n9. 'cat8' - 'A', 'B', 'C', 'D', 'E', 'F', 'G' can be changed to 1, 2, 3, 4, 5, 6, 7 respectively.\n10. 'cat9' - 'A'- 'O' sequence of alphabetical letters can be changed to values ranging from 1 to 15 respectively. ","metadata":{}},{"cell_type":"code","source":"# encoding the first 10 columns as numbers in kaggle_tr dataframe\n\nkaggle_tr['cat0'].replace(['A', 'B'], [1, 2], inplace = True)\nkaggle_tr['cat1'].replace(['A', 'B'], [1, 2], inplace = True)\nkaggle_tr['cat2'].replace(['A', 'B'], [1, 2], inplace = True)\nkaggle_tr['cat3'].replace(['A', 'B', 'C', 'D'], [1, 2, 3, 4], inplace = True)\nkaggle_tr['cat4'].replace(['A', 'B', 'C', 'D'], [1, 2, 3, 4], inplace = True)\nkaggle_tr['cat5'].replace(['A', 'B', 'C', 'D'], [1, 2, 3, 4], inplace = True)\nkaggle_tr['cat6'].replace(['A', 'B', 'C', 'D', 'E', 'G', 'H', 'I'], [1, 2, 3, 4, 5, 6, 7, 8],\\\n                                     inplace = True)\nkaggle_tr['cat7'].replace(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I'], [1, 2, 3, 4, 5, 6, 7, 8],\\\n                                     inplace = True)\nkaggle_tr['cat8'].replace(['A', 'B', 'C', 'D', 'E', 'F', 'G'], [1, 2, 3, 4, 5, 6, 7],\\\n                                     inplace = True)\nkaggle_tr['cat9'].replace(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', \\\n                                      'K', 'L', 'M', 'N', 'O'], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\\\n                                                                12, 13, 14, 15], inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_tr.iloc[:, 0:10] = kaggle_tr.iloc[:, 0:10].astype('category')\n\nkaggle_tr.iloc[:, 0:10] = kaggle_tr.iloc[:, 0:10].astype('category')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving features in kaggle_feat dataframe\nkaggle_feat = kaggle_tr.drop(['target'], axis = 1)\n\n# saving target variable in kaggle_target dataframe\nkaggle_target = kaggle_tr['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting kaggle_features and kaggle_label into training and validation sets\n\nkaggle_feat_train_pre, kaggle_feat_val_pre, kaggle_label_train_pre, \\\nkaggle_label_val_pre = train_test_split(kaggle_feat, kaggle_target, train_size = 0.8,\\\n                                        test_size = 0.2, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_feat_val_pre.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_feat_train_pre.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_feat_train_pre.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_feat_val_pre.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are not scaling the numerical features in training and validation data as it is not required before performing regression by using algorithms such as RandomForestRegressor and XGBRegressor","metadata":{}},{"cell_type":"code","source":"# checking the number of observations in training and validation data \n\nprint(\"The training data with features has {} rows and {} columns\".format(kaggle_feat_train_pre.shape[0], \n                                                            kaggle_feat_train_pre.shape[1]))\n\nprint(\"The validation data with features has {} rows and {} columns\".format(kaggle_feat_val_pre.shape[0], \n                                                            kaggle_feat_val_pre.shape[1]))\n\nprint(\"The training data with label has {} observations\".format(kaggle_label_train_pre.shape))\n\nprint(\"The validation data with label has {} observations\".format(kaggle_label_val_pre.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining a function to evaluate the regression model using the metric of RMSE or root mean square\n# error as per the competition guidelines by Kaggle\n\nmodel = RandomForestRegressor(n_estimators = 100, random_state = 0)\nmodel.fit(kaggle_feat_train_pre, kaggle_label_train_pre)\npredictions = model.predict(kaggle_feat_val_pre)\nregress_a = mean_squared_error(kaggle_label_val_pre, predictions, squared = False)\n\nregress_a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regress_a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above baseline regression performed returned a RMSE of approximately 0.74. Using this value, we will evaluate other predictions made by using regression algorithms. ","metadata":{}},{"cell_type":"code","source":"# now, we will calculate importance of features to understand their contributions in predictions \n# using feature_importances_ method from Random Forest \n\n# first, we will use features_importances_ attribute from sklearn's RandomForestRegressor algorithm\n\nimportances = model.feature_importances_\n\nimportances","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# storing the feature column names in a dataframe\n\ncols = list(kaggle_tr.columns)\ncols.remove('target')\nlist_features = [i for i in cols]\n\nfeat_importances = pd.Series(importances, index = list_features)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, plotting the values of feature importances against names of features \n# for better visualization and understanding\n\nplt.figure(figsize = (10,10))\nfeat_importances.nlargest(20).plot(kind='barh')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interpretation:\n\nWe can observe that the first 10 categorical features have carried not much importance in the regression model. We can remove them to build another model to check whether predictions are more accurate in terms of lower RMSE. However, it is important to keep in consideration the fact that result of feature_importances_ attribute can be influenced by features with high cardinality or many unique values and thus, it may not represent the actual picture. Overall, the above plot shows that 'cont12', 'cont10', 'cont2', 'cont9', 'cont5', 'cont7', 'cont13', 'cont3', 'cont4', 'cont11', 'cont0', 'cont6', 'cont8', 'cont1' comprise of the features carrying the highest importances in descending order among all the features used for building the model.  ","metadata":{}},{"cell_type":"code","source":"# checking the number of unique values in each feature to understand the cardinality that\n# could have influenced the results in the above plot\n\nfor i in kaggle_feat_train_pre.columns:\n    print(\"The number of unique values in {} is {} \\n\".format(i, kaggle_feat_train_pre[i].nunique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Important Observations:**\n\nIt was demonstrated in the Kaggle tutorial on machine learning that only categorical variables with \nnot high cardinality i.e.; less than 10 unique values are considered for regression to have better predictions. Since 'cont9' has more than 10 unique values, it suggests the case of high cardinality. \n\nMoreover, it can be observed in the output of above code expression that minimum 239621 continuous values out of total 240000 continuous values along the rows in training data are unique and that suggests  there are more than 99% of total unique observations along the rows for each of the features in training data. feature_importances_ attribute is more biased towards high cardinality features and shows those features as more important than other independent variables. \n\nPlease refer to the example in the following link that describes how high cardinality continuous values are addressed through feature engineering on another important dataset on Titanic provided by Kaggle competitions. The example is given in the official documentation of scikit-learn. SimpleImputer algorithm is used to impute the high cardinality features with mean values. https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html?highlight=cardinality","metadata":{}},{"cell_type":"code","source":"# now checking the unique values or cardinality in complete dataset, kaggle_tr to have an idea of \n# the kind of cardinality that we have to address \n\nfor i in list_features:\n    print(\"The number of unique values in {} is {} \\n\".format(i, kaggle_tr[i].nunique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observations: \n\nWe observed similar results when we checked the total number of unique values or cardinality \nof each of the features in complete dataset i.e.; kaggle_tr. There are at least 99.8% unique values in continuous features in the dataset. The feature, 'cat9' particularly has high cardinality as there are more than 10 unique values in that discrete feature and that is high as per the recommendation of Kaggle tutorial. \n\nBefore dealing with cardinality, we will first evaluate the important features generated by other methods for comparison such as permutation based feature importance. ","metadata":{}},{"cell_type":"code","source":"# calculating permutation-based importance, which is not much influenced by high cardinality features\n# but the results of permutation-based importance are influenced if there is high correlation between \n# features \n# estimating permutation-based feature importances on the validation set\n\n# importing necessary attributes from sklearn\n\nfrom sklearn.inspection import permutation_importance\n\nperm_importance = permutation_importance(model, kaggle_feat_val_pre, kaggle_label_val_pre)\n\npermutations_imp = pd.Series(perm_importance.importances_mean, index = list_features)\n\npermutations_imp.sort_values(ascending = False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, plotting the values of permutation-based feature importances against names of features \n# for better visualization and understanding\n\nplt.figure(figsize = (10,10))\npermutations_imp.nlargest(20).plot(kind = 'barh')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interpretation:\n\nAbove plot shows that 'cont12', 'cont10', 'cont2','cont5', and 'cont9' carry higher importance among other features in the dataset. Thus, it is clearly observed that the some of the important features depicted in the above plot are very different from those in the previous plot. It was also observed earlier that there is weak correlation between the continuous values in the given dataset in this competition assignment but 'cont12' and 'cont10' are still found to be the most correlated ones among other continuous features. \n\nSince the permutation-based feature importance method is checked on the validation sets used in the RandomForest model, we will also apply this method on the training set to check any possibilities of over-fitting by comparing the visualization on plot made using the training set.","metadata":{}},{"cell_type":"code","source":"# estimating importance of features by using permutation-based feature importance method\n# on the training set for comparison with the results evident in the previous plot\n\nperm_importance1 = permutation_importance(model, kaggle_feat_train_pre, kaggle_label_train_pre)\n\npermutations_imp1 = pd.Series(perm_importance1.importances_mean, index = list_features)\n\npermutations_imp1.sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, plotting the values of permutation-based feature importances estimated on the training set \n# against names of features \n# for better visualization and understanding\n\nplt.figure(figsize = (10,10))\npermutations_imp1.nlargest(20).plot(kind = 'barh')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above two plots that depict permutation-based feature importances on the training and \nvalidation sets clearly show that the ranking of most important features namely, 'cont12', 'cont10', 'cont2'remains unchanged in both the plots. the order of 'cont9' and 'cont5' is changed in training and validation data. So, there could be the scenario of overfitting as there is difference between the ranks assigned according to the importance of features. ","metadata":{}},{"cell_type":"markdown","source":"Overall Inference:\n\nNow, a copy of the kaggle_train dataframe is created and then the dataframe will be segregated into training and validation sets to build a baseline model using RandomForestRegressor. With respect to this baseline model, regression models with lower RMSE (root mean square error) values will be created and unknown features will be tackled by using principal component analysis. However, it is important to consider that the use of RandomForestRegressor algorithm demands that the analyst enters a specific number of decision trees to average out their predictions, the maximum number of features that will inform the splitting at each node, and maximum depth or number of levels in each decision tree. Since the given dataset has 24 features and 3,00,000 observations and there is no information available about the features present in the dataset, it is quite difficult to build an optimal model with optimal depth and choose the optimal number of features required for splitting at each node that is required to perform hyperparameter tuning in Random Forest. Moreover, we have already observed that there are no strong linear relationships between the numerical variables and the target variable. Hence, mutual information need to be used to identify all other kinds of relationships, if any, between the target variable and features in the dataset. It is crucial to understand the significance of features to the target variable. ","metadata":{}}]}